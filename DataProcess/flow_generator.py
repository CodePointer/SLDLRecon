# -*- coding: utf-8 -*-

"""
This file is to process data processed by coord_generator.py
Data generated by OpenGL:
    depth_cam, depth_pro1, depth_pro2 -- from different views;
    Binary files;
    No mask info.
Data processed by coord_generator.py:
    prefix = 'm%02df%03d' % (idx_set[idx][0], idx_set[idx][1])
        np.save('%s/%s_depth_cam.npy' % (file_path, prefix), depth_cam)
        plt.imsave('%s/%s_mask_cam.png' % (file_path, prefix), mask_cam, cmap='Greys_r')
        np.save('%s/%s_depth_pro1.npy' % (file_path, prefix), depth_pro1)
        plt.imsave('%s/%s_mask_pro1.png' % (file_path, prefix), mask_pro1, cmap='Greys_r')
        np.save('%s/%s_xy_pro1_cv.npy' % (file_path, prefix), xy_pro1_cv)
        np.save('%s/%s_xy_cam_p1v.npy' % (file_path, prefix), xy_cam_p1v)
        plt.imsave('%s/%s_shade_cam.png' % (file_path, prefix), shade_cam.reshape(image_shape), cmap='Greys_r')
        plt.imsave('%s/%s_shade_pro1.png' % (file_path, prefix), shade_pro1.reshape(image_shape), cmap='Greys_r')
        print('%s/%s writing finished.' % (file_path, prefix))
Main work:
    1. Set jump value for flow calculation.
        The jump value is used for frame calculation. Flow will be calculated with i and i+jump frame.
        Default: 1
    2. Load needed information. Including:
        depth_cam(only load and save)
        mask_cam(only load and save)
        xy_pro1_cv.npy
        xy_cam_p1v_j.npy
        mask_pro1_j.png
        shade_cam.png
        pattern.png (For image generation)
    3. Calculate flow by using grid_sample.
        (https://pytorch.org/docs/stable/nn.html?highlight=grid_sample#torch.nn.functional.grid_sample)
        sample xy_cam_p1v_j.npy, by using xy_pro1_cv.npy.
        Get: xy_cam_cv_j.npy
        With xy_cam_cv.npy, calculate flow1_j1.npy.
        Also, sample mask_pro1_j.png to get mask_flow1.png.
    4. Draw patterns on the depth map. (With noise)
        a) Pattern noise. Added on every pixel of pattern.
        b) Shading effect. Plus shade mat for image rendering.
        c) Image noise. Added on every pixel of image.
        sample pattern.png, by using xy_pro1_cv.npy.
        Get: img_cam.png
    5. Save information
        depth_cam(only load and save)
        mask_cam(only load and save)
        flow1_j1.npy
        mask_flow1.png
        img_cam.png
"""

import csv
import sys
import os
import torch
from matplotlib import pyplot as plt
import numpy as np
import scipy.stats as st


def gkern(kernlen=21, nsig=3.0):
    """Returns a 2D Gaussian kernel array."""
    interval = (2*nsig+1.0) / kernlen
    x = np.linspace(-nsig-interval/2.0, nsig+interval/2.0, kernlen+1)
    kern1d = np.diff(st.norm.cdf(x))
    kernel_raw = np.sqrt(np.outer(kern1d, kern1d))
    kernel = kernel_raw / kernel_raw.sum()
    return kernel


def load_as_torch(name, suffix, main_path, prefix, dtype=np.float32):
    """Load file as torch tensor.

    Possible data:
        depth_cam.npy   [H, W], float
        mask_cam.png    [H, W], byte
        xy_pro1_cv.npy  [H, W, 2], float
        xy_cam_p1v.npy  [H, W, 2], float
        mask_pro.png    [H, W], byte

    Args:
        :param name: the data name.
        :param suffix: '.png' or '.npy'.
        :param main_path: the file path with all the m00f000 data.
        :param prefix: m00f000.

    Return:
        :return: Loaded data or None(if suffix is not available).
                Data is always 4D [N, C, H, W].

    Raises:
        None.
    """
    full_name = '%s/%s_%s%s' % (main_path, prefix, name, suffix)
    if suffix == '.png':
        item = torch.from_numpy(plt.imread(full_name).astype(dtype))
        if len(item.shape) == 3:
            item = item[:, :, 0].unsqueeze(0)
        else:
            item = item.unsqueeze(0)
        item = item.unsqueeze(0)
        return item.cuda()
    elif suffix == '.npy':
        item = torch.from_numpy(np.load(full_name).astype(dtype))
        if len(item.shape) == 2:
            item = item.unsqueeze(0)
        else:
            item = item.permute(2, 0, 1)
        item[torch.isnan(item)] = 0
        item = item.unsqueeze(0)
        return item.cuda()
    else:
        return None


def save_from_torch(mat, name, suffix, out_path, prefix):
    """Save file from torch tensor to npy or png file.

    detach, cpu, numpy. use plt.imsave and np.save function.

    :param name:
    :param suffix:
    :param out_path:
    :param prefix:
    :return:
    """
    full_name = '%s/%s_%s%s' % (out_path, prefix, name, suffix)
    if suffix == '.png':
        mat_np = mat.detach().cpu().squeeze().numpy()
        plt.imsave(full_name, mat_np, cmap='Greys_r')
    elif suffix == '.npy':
        mat = mat.detach().cpu().squeeze()
        if len(mat.shape) == 3:
            mat = mat.permute(1, 2, 0)
        mat_np = mat.numpy().astype(np.float32)
        np.save(full_name, mat_np)


def main():

    # Some parameters (You should edit here every time):
    main_path = '/media/qiao/数据文档/SLDataSet/Thing10K/2_DepthWithCorres/train_corres'
    out_path = '/media/qiao/数据文档/SLDataSet/Thing10K/3_PatternedImage/train_dataset'
    pattern_path = '/media/qiao/数据文档/SLDataSet/Thing10K/3_PatternedImage'
    model_num = 50
    frame_num = 100
    jump = 1
    cam_shape = (1024, 1280)
    pro_shape = (800, 1280)
    flow_thred = 8.0
    pattern_pix_size = 4
    # Noise parameters
    p_noise_rad = 0.2
    i_noise_rad = 0.2
    gker_rad = 4
    kernlen = gker_rad * 2 + 1
    gkernel = torch.from_numpy(gkern(kernlen=kernlen, nsig=4.0)).reshape(1, 1, kernlen, kernlen)
    gkernel = gkernel.float().cuda()

    # Main Loop
    if not os.path.exists(out_path):
        os.mkdir(out_path)
    x_cam_grid = torch.arange(0, cam_shape[1]).reshape(1, -1).repeat(cam_shape[0], 1)
    y_cam_grid = torch.arange(0, cam_shape[0]).reshape(-1, 1).repeat(1, cam_shape[1])
    xy_cam_grid = torch.stack((x_cam_grid, y_cam_grid), dim=0).reshape(1, 2, cam_shape[0], cam_shape[1]).float()
    xy_cam_grid = xy_cam_grid.cuda()
    pattern = load_as_torch('pattern0', '.png', pattern_path, '%dpix' % pattern_pix_size, dtype=np.float32)
    # pattern = pattern / 255.0
    for m_idx in range(1, model_num + 1):
        # Step 1: Load all information needed.
        print("Loading No.%02d model..." % m_idx, end='', flush=True)
        depth_cam = []
        mask_cam = []
        xy_pro1_cv = []
        xy_cam_p1v = []
        mask_pro1 = []
        shade_cam = []
        for f_idx in range(0, frame_num):
            prefix = 'm%02df%03d' % (m_idx, f_idx)
            depth_cam.append(load_as_torch('depth_cam', '.npy', main_path, prefix, dtype=np.float32))
            mask_cam.append(load_as_torch('mask_cam', '.png', main_path, prefix, dtype=np.uint8))
            xy_pro1_cv.append(load_as_torch('xy_pro1_cv', '.npy', main_path, prefix, dtype=np.float32))
            xy_cam_p1v.append(load_as_torch('xy_cam_p1v', '.npy', main_path, prefix, dtype=np.float32))
            mask_pro1.append(load_as_torch('mask_pro1', '.png', main_path, prefix, dtype=np.uint8))
            shade_cam.append(load_as_torch('shade_cam', '.png', main_path, prefix, dtype=np.float32))
        print("Finished.")

        # Step 2: Process every frame, calculate flow.
        img_cam_list = []
        for f_idx in range(0, frame_num):
            prefix = 'm%02df%03d' % (m_idx, f_idx)
            i = f_idx
            j = i + jump
            if j >= frame_num:
                j -= frame_num
            # xy_pro1_cv to [-1, 1]
            xy_pro1_cv[i][:, 0, :, :] = xy_pro1_cv[i][:, 0, :, :] / (pro_shape[1] - 1) * 2.0 - 1.0
            xy_pro1_cv[i][:, 1, :, :] = xy_pro1_cv[i][:, 1, :, :] / (pro_shape[0] - 1) * 2.0 - 1.0
            xy_pro1_cv[i][mask_cam[i].repeat(1, 2, 1, 1) == 0] = -1
            xy_pro1_cv[i] = xy_pro1_cv[i].permute(0, 2, 3, 1)  # [N(1), H, W, 2]

            # Sample xy_cam_cv from xy_cam_p1v_j
            xy_cam_cv = torch.nn.functional.grid_sample(input=xy_cam_p1v[j].float(), grid=xy_pro1_cv[i].float())
            mask_flow = torch.nn.functional.grid_sample(input=mask_pro1[j].float(), grid=xy_pro1_cv[i].float())
            mask_flow[mask_flow < 0.99] = 0
            mask_flow[mask_flow > 0] = 1
            xy_cam_cv[mask_flow.repeat(1, 2, 1, 1) == 0] = 0

            # Sample img_cam from xy_cam_p1v
            # pattern noise here
            noise_shape = tuple(int(i / pattern_pix_size) for i in pro_shape)
            pattern_noise = torch.randn(pattern.shape[:2] + noise_shape).cuda() * p_noise_rad
            pattern_noise_up = torch.nn.functional.interpolate(input=pattern_noise, scale_factor=pattern_pix_size,
                                                               mode='nearest')
            pattern_add = pattern + pattern_noise_up
            img_cam = torch.nn.functional.grid_sample(input=pattern_add, grid=xy_pro1_cv[i].float())
            # shade_noise here
            shade_img = img_cam * shade_cam[i]
            # shade_img = img_cam
            # image_noise here
            img_noise = torch.randn(cam_shape).cuda() * i_noise_rad
            img_cam = shade_img + img_noise
            img_cam = torch.nn.functional.conv2d(img_cam, gkernel, padding=gker_rad)
            img_cam[mask_cam[i] == 0] = 0
            img_cam = torch.clamp(img_cam, min=0, max=1)

            # Calculate flow mat and check valid
            flow_j = xy_cam_cv - xy_cam_grid
            mask_flow[torch.abs(flow_j[:, :1, :, :]) > flow_thred] = 0
            mask_flow[torch.abs(flow_j[:, 1:, :, :]) > flow_thred] = 0
            flow_j[mask_flow.repeat(1, 2, 1, 1) == 0] = 0

            # Save (as i frame)
            # save_from_torch(depth_cam[i].float(), 'depth_cam', '.npy', out_path, prefix)
            # save_from_torch(mask_cam[i], 'mask_cam', '.png', out_path, prefix)
            # save_from_torch(flow_j.float(), 'flow1_cv', '.npy', out_path, prefix)
            # save_from_torch(mask_flow.float(), 'mask_flow1', '.png', out_path, prefix)
            save_from_torch(img_cam, 'img_cam_1', '.png', out_path, prefix)
            img_cam_list.append(img_cam)

            if i % 5 == 4:
                print('.', end='', flush=True)
        print('')

        # Save img_cam_2
        for f_idx in range(0, frame_num):
            prefix = 'm%02df%03d' % (m_idx, f_idx)
            i = f_idx
            j = i + jump
            j = j if j < frame_num else j - frame_num
            save_from_torch(img_cam_list[j], 'img_cam_2', '.png', out_path, prefix)


if __name__ == '__main__':
    assert len(sys.argv) >= 1

    main()
